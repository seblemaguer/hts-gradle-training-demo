buildscript {
    repositories {
        mavenLocal()
        mavenCentral()
        jcenter()
    }

    dependencies {
        classpath group:"de.dfki.mary", name:"marytts-analysis", version: "0.1"
    }
}

plugins {
  id 'distribution'
  id 'maven-publish'
}



ext {
    utilsDir = file("$rootDir/utils")
}


import marytts.analysis.distances.acoustic.*;
import marytts.analysis.distances.graphic.*;
import marytts.analysis.distances.string.*;
import marytts.analysis.Statistics;
import marytts.analysis.alignment.IDAlignment;
import marytts.analysis.utils.LoadingHelpers;
import groovy.json.*

/***************************************************************************************************
 ***
 ***************************************************************************************************/

def map_class_phone = ["aa": "vowel",
"ae": "vowel",
"ah": "vowel",
"an": "vowel",
"ao": "vowel",
"aw": "vowel",
"ax": "vowel",
"axr": "approximant",
"ay": "vowel",
"b": "labial",
"ch": "coronal",
"d": "coronal",
"dh": "coronal",
"eh": "vowel",
"el": "coronal",
"em": "labial",
"en": "coronal",
"er": "approximant",
"ey": "vowel",
"f": "labial",
"g": "dorsal",
"hh": "glottal",
"ih": "vowel",
"ix": "vowel",
"iy": "vowel",
"jh": "coronal",
"k": "dorsal",
"l": "coronal",
"m": "labial",
"n": "coronal",
"ng": "dorsal",
"oo": "vowel",
"ow": "vowel",
"oy": "vowel",
"p": "labial",
"pau": "silence",
"r": "approximant",
"s": "coronal",
"sh": "coronal",
"t": "coronal",
"th": "coronal",
"uh": "vowel",
"ur": "approximant",
"uw": "vowel",
"v": "labial",
"w": "labial",
"y": "vowel",
"z": "coronal",
"zh": "coronal"]

// Specific to this architecture (FIXME: maybe generalize it ?)
def eval_name = System.getProperty("eval_name")
def synth_dir = "${rootProject.projectDir}/../synthesis/build/output"
def nat_dir = "${rootProject.projectDir}/../extraction/build"
def model_file = "${rootProject.projectDir}/../training/build/raw/"

def slurper = new JsonSlurper()
def config_file =  new File("$model_file/config.json")
def config = slurper.parseText( config_file.text )

def list_file = new File(DataFileFinder.getFilePath("list_test"))

def nat_lab_dir = DataFileFinder.getFilePath(config.data.mono_lab_dir)
def list = "list_test"

def channels = ["T3", "T2", "T1", "ref", "jaw", "upperlip", "lowerlip"]
if (eval_name.contains("weight") || eval_name.contains("tongue")) {
    channels = ["T3", "T2", "T1", "ref"]
}


/*******************************************************************************************
 ** Utils
 *******************************************************************************************/
task adaptDurToLab() {

    list_file.eachLine { line ->
        outputs.files "$buildDir/lab/${line}.lab"
    }

    doLast {
        // FIXME: tmp for debug
        (new File("$buildDir/lab")).mkdirs()
        list_file.eachLine { line ->
            exec {
                commandLine "perl", "utils/duration2htk.pl", "${synth_dir}/normal/${line}.dur", "$buildDir/lab/${line}.lab"
            }
        }
    }
}

task JSONToEMA() {
    doLast {
        (new File("$buildDir/ema/ori")).mkdirs()

        list_file.eachLine { line ->
            exec {
                commandLine "python3 json2ema.py $buildDir/$eval_name/ema_analysis/json/${line}.json $buildDir/ema/ori/${line}.ema".tokenize()
                workingDir rootProject.ext.utilsDir
            }
        }

        // Test
        (new File("$buildDir/ema/gen")).mkdirs()
        list_file.eachLine { line ->
            exec {
                commandLine "python3 json2ema.py $synth_dir/imposed_dur/${line}.json $buildDir/ema/gen/${line}.ema".tokenize()
                workingDir rootProject.ext.utilsDir
            }
        }
    }
}

/*******************************************************************************************
 ** Global distances
 *******************************************************************************************/
task computeRMSEF0() {
    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_f = new File("$buildDir/$eval_name/global/rms_f0.csv")
    outputs.files output_f
    doLast {
        def loading = new LoadingHelpers();
        output_f.text = "#id\trms(cent)\n"

        list_file.eachLine { line ->
            //
            double[][] src = loading.loadFloatBinary("${nat_dir}/lf0/${line}.lf0", 1);
            double[][] tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.lf0", 1);

            def nb_frames = Math.min(src.length, tgt.length)
            for (int i=0; i<nb_frames; i++)
            {
                if (src[i][0] != -1.0e+10)
                {
                    src[i][0] = Math.exp(src[i][0])
                }
                else
                {
                    src[i][0] = 0;
                }

                if (tgt[i][0] != -1.0e+10)
                {
                    tgt[i][0] = Math.exp(tgt[i][0])
                }
                else
                {
                    tgt[i][0] = 0;
                }
            }

            // Generate path
            def alignment = new IDAlignment(nb_frames);
            def v = new CentRMS(src, tgt, 0.0);
            Double d = v.distancePerUtterance(alignment);
            output_f << "$line\t$d\n";
        }
    }
}

task computeVUVRate() {
    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_f = new File("$buildDir/$eval_name/global/voice_error.csv")
    outputs.files output_f
    doLast {
        def loading = new LoadingHelpers();
        output_f.text = "#id\tvoice_error\n"

        list_file.eachLine { line ->
            //
            double[][] src = loading.loadFloatBinary("${nat_dir}/lf0/${line}.lf0", 1);
            double[][] tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.lf0", 1);

            def nb_frames = Math.min(src.length, tgt.length)
            for (int i=0; i<nb_frames; i++)
            {
                if (src[i][0] != -1.0e+10)
                {
                    src[i][0] = Math.exp(src[i][0])
                }
                else
                {
                    src[i][0] = 0;
                }

                if (tgt[i][0] != -1.0e+10)
                {
                    tgt[i][0] = Math.exp(tgt[i][0])
                }
                else
                {
                    tgt[i][0] = 0;
                }
            }

            // Generate path
            def alignment = new IDAlignment(nb_frames);
            def v = new VoicingError(src, tgt, 0.0);
            Double d = v.distancePerUtterance(alignment);
            output_f << "$line\t$d\n";
        }
    }
}

task computeRMSEEMA() {

    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_f = new File("$buildDir/$eval_name/global/rms_ema.csv")
    outputs.files output_f
    doLast {
        def loading = new LoadingHelpers();
        output_f.text = "#id\trmse\n"

        list_file.eachLine { line ->
            //
            double[][] src = loading.loadFloatBinary("${nat_dir}/ema/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
            double[][] tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size

            def nb_frames = Math.min(src.length, tgt.length)

            // Generate path
            def alignment = new IDAlignment(nb_frames);
            def v = new RMS(src, tgt, channels.size()*3); // FIXME: hardcoded frame size
            Double d = v.distancePerUtterance(alignment);
            output_f << "$line\t$d\n";
        }
    }
}

task computeEucDistEMA() {

    if (eval_name.contains("weight")) {
         // dependsOn JSONToEMA
    }

    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_handles = []
    channels.each { c ->
        output_handles << new File("$buildDir/$eval_name/global/euc_dist_${c}.csv")
        outputs.files output_handles
    }

    doLast {
        output_handles.each {f ->
            f.text = "# euc. dist. (cm)\n"
        }
        def loading = new LoadingHelpers();
        list_file.eachLine { line ->

            // FIXME: stupid weight again
            double[][] src;
            double[][] tgt;
            if (eval_name.contains("weight"))
            {
                //
                src = loading.loadFloatBinary("$buildDir/ema/ori/${line}.ema",channels.size()*3); // FIXME: hardcoded frame size
                tgt = loading.loadFloatBinary("$buildDir/ema/gen/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
            }
            else
            {
                //
                src = loading.loadFloatBinary("${nat_dir}/ema/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
                tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
            }

            // FIXME: hardcoded frame size
            int nb_frames = Math.min(src.length, tgt.length)
            for (int j=0; j<channels.size()*3; j+=3)
            {
                double[][] real_src = new double[nb_frames][3];
                double[][] real_tgt = new double[nb_frames][3];

                for (int i=0; i<nb_frames; i++)
                {
                    for (int k=0; k<3; k++)
                    {
                        real_src[i][k] = src[i][j+k]
                        real_tgt[i][k] = tgt[i][j+k] / 10
                    }
                }


                def v = new EuclidianDistance(real_src, real_tgt, 3);
                for (int i=0; i<nb_frames; i++)
                {
                    output_handles[(j/3).intValue()] << v.distancePerFrame(i, i) << "\n"
                }
            }
        }
    }
}

task computeRMSEDur() {
    dependsOn adaptDurToLab

    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_f = new File("$buildDir/$eval_name/global/rms_dur.csv")
    outputs.files output_f

    doLast {

        output_f.text = "#id\trms (ms)\n"

        list_file.eachLine { line ->

            // Loading first label
            def ref_dur_list = []
            (new File("$nat_lab_dir/${line}.lab")).eachLine { label -> // FIXME: hardcoded reference name
                def elts = label.split()
                ref_dur_list << (elts[1].toInteger() - elts[0].toInteger())/ 10000
            }
            double[][] ref_dur = new double[ref_dur_list.size()][1];
            ref_dur_list.eachWithIndex {val, idx ->
                ref_dur[idx][0] = val
            }

            // Loading first label
            def synth_dur_list = []
            (new File("$buildDir/lab/${line}.lab")).eachLine { label -> // FIXME: hardcoded synth name
                def elts = label.split()
                synth_dur_list << (elts[1].toInteger() - elts[0].toInteger())/ 10000
            }

            double[][] synth_dur = new double[synth_dur_list.size()][1];
            synth_dur_list.eachWithIndex {val, idx ->
                synth_dur[idx][0] = val
            }

            if (synth_dur.length != ref_dur.length) {
                throw new Exception("what ?");
            }


            // Generate path
            def alignment = new IDAlignment(synth_dur.length);
            def v = new RMS(ref_dur, synth_dur, 1);
            Double d = v.distancePerUtterance(alignment);
            output_f << "$line\t$d\n";
        }
    }
}

task computeMCDIST() {

    (new File("$buildDir/$eval_name/global")).mkdirs()
    def output_f = new File("$buildDir/$eval_name/global/mcdist.csv")
    outputs.files output_f
    doLast {
        def loading = new LoadingHelpers();
        output_f.text = "#id\tmcdist\n"

        list_file.eachLine { line ->
            //
            double[][] src = loading.loadFloatBinary("${nat_dir}/mgc/${line}.mgc", 50); // FIXME: hardcoded frame size
            double[][] tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.mgc", 50); // FIXME: hardcoded frame size

            def nb_frames = Math.min(src.length, tgt.length)

            // Generate path
            def alignment = new IDAlignment(nb_frames);
            def v = new CepstralDistorsion(src, tgt, 50); // FIXME: hardcoded frame size
            Double d = v.distancePerUtterance(alignment);
            output_f << "$line\t$d\n";
        }
    }
}

task generateGlobalReport() {

    def ema_activated = false
    def lf0_activated = false
    def mgc_activated = false
    def bap_activated = false

    config.models.cmp.streams.each { stream ->
        if (stream.kind == "lf0") {
            lf0_activated = true
            dependsOn computeRMSEF0, computeVUVRate
        }

        if (stream.kind == "mgc") {
            mgc_activated = true
            dependsOn computeMCDIST
        }

        /*
          if (stream.kind == "bap") {
          bap_activated = true
          dependsOn computeRMSEBAP
          }
        */

        if (stream.kind == "ema") {
            ema_activated = true
            dependsOn computeRMSEEMA, computeEucDistEMA
        }

        if (stream.kind == "weight") {
            ema_activated = true
            dependsOn computeEucDistEMA
        }
    }

    dependsOn computeRMSEDur

    def input_rms_f0 = new File("$buildDir/$eval_name/global/rms_f0.csv")
    def input_vuvrate = new File("$buildDir/$eval_name/global/voice_error.csv")
    def input_mcdist = new File("$buildDir/$eval_name/global/mcdist.csv")
    def input_rms_dur = new File("$buildDir/$eval_name/global/rms_dur.csv")
    def input_rms_bap = new File("$buildDir/$eval_name/global/rms_bap.csv")
    def input_rms_ema = new File("$buildDir/$eval_name/global/rms_ema.csv")
    def ema_input_file = []
    channels.each { c -> ema_input_file << new File("$buildDir/$eval_name/global/euc_dist_${c}.csv")}


    def output_f = new File("$buildDir/report.csv")
    outputs.files output_f

    doLast {

        output_f.text = "#id\tmean\tstd\tconfint\n"

        // RMS DUR part
        def values = []
        input_rms_dur.eachLine { line ->
            if (line.startsWith("#"))
                return; // Continue...

                def elts = line.split()
                values << Double.parseDouble(elts[1])
        }
        def dist = new Double[values.size()];
        values.toArray(dist);
        def s = new Statistics(dist);
        output_f << "rms dur\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"


        // RMS F0 part
        if (lf0_activated) {
            values = []
            input_rms_f0.eachLine { line ->
                if (line.startsWith("#"))
                    return; // Continue...

                    def elts = line.split()
                    values << Double.parseDouble(elts[1])
            }
            dist = new Double[values.size()];
            values.toArray(dist);
            s = new Statistics(dist);
            output_f << "rms f0\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"


            // Voice/Unvoice error rate part
            values = []
            input_vuvrate.eachLine { line ->
                if (line.startsWith("#"))
                    return; // Continue...

                    def elts = line.split()
                    values << Double.parseDouble(elts[1])
            }
            dist = new Double[values.size()];
            values.toArray(dist);
            s = new Statistics(dist);
            output_f << "vuvrate\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"
        }

        // Mel CepstralDistorsion part
        if (mgc_activated) {
            values = []
            input_mcdist.eachLine { line ->
                if (line.startsWith("#"))
                    return; // Continue...

                    def elts = line.split()
                    values << Double.parseDouble(elts[1])
            }
            dist = new Double[values.size()];
            values.toArray(dist);
            s = new Statistics(dist);
            output_f << "mcdist\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"
        }

        // RMS EMA part
        if (ema_activated) {
            values = []
            // input_rms_ema.eachLine { line ->
            //     if (line.startsWith("#"))
            //         return; // Continue...

            //         def elts = line.split()
            //         values << Double.parseDouble(elts[1])
            // }
            // dist = new Double[values.size()];
            // values.toArray(dist);
            // s = new Statistics(dist);
            // output_f << "rms ema\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"


            ema_input_file.eachWithIndex { c_file,i ->

                values = []
                c_file.eachLine { line ->
                    if (line.startsWith("#"))
                        return; // Continue...

                        values << Double.parseDouble(line)
                }
                dist = new Double[values.size()];
                values.toArray(dist);
                s = new Statistics(dist);
                output_f << "euc dist ${channels[i]} (cm)\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"
            }
        }
    }
}

/*******************************************************************************************
 ** Specific distances
 *******************************************************************************************/
task computeEucDistEMAPerPhoneme() {
    dependsOn adaptDurToLab

    if (eval_name.contains("weight")) {
         // dependsOn JSONToEMA
    }

    (new File("$buildDir/$eval_name/global")).mkdirs()
    def raw_output_f = new File("$buildDir/$eval_name/global/dist_euc_ema_per_phoneme.csv")
    outputs.files raw_output_f

    doLast {
        // Initialisation
        def loading = new LoadingHelpers();
        def val = []
        raw_output_f.withWriter('UTF-8') { writer ->
            writer.write("#utt\tid_frame\tlabel\tcoil\teuc_dist(mm)\n")
        list_file.eachLine { line ->

            // FIXME: stupid weight again
            double[][] src;
            double[][] tgt;
            if (eval_name.contains("weight"))
            {
                //
                src = loading.loadFloatBinary("$buildDir/ema/ori/${line}.ema",channels.size()*3); // FIXME: hardcoded frame size
                tgt = loading.loadFloatBinary("$buildDir/ema/gen/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
            }
            else
            {
                //
                src = loading.loadFloatBinary("${nat_dir}/ema/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
                tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${line}.ema", channels.size()*3); // FIXME: hardcoded frame size
            }

            // Loading first label
            def ref_dur_list = []
            (new File("$nat_lab_dir/${line}.lab")).eachLine { label -> // FIXME: hardcoded reference name
                def elts = label.split()

                def start = (elts[0].toInteger() / (10000 * 5)).intValue()
                def end = (elts[1].toInteger() / (10000 * 5)).intValue()

                // FIXME: hardcoded frame size
                int nb_frames = end - start
                for (int j=0; j<channels.size()*3; j+=3)
                {
                    double[][] real_src = new double[nb_frames][3];
                    double[][] real_tgt = new double[nb_frames][3];
                    for (int i=0; i<nb_frames; i++)
                    {
                        for (int k=0; k<3; k++)
                        {
                            real_src[i][k] = src[i][j+k]
                            real_tgt[i][k] = tgt[i][j+k] / 10
                        }
                    }

                    def v = new EuclidianDistance(real_src, real_tgt, 3);

                    for (int i=0; i<nb_frames; i++)
                    {
                        writer.write(line + "\t" + (start + i) + "\t" + elts[2]  + "\t" + channels[(j/3).intValue()] + "\t" + v.distancePerFrame(i, i) + "\n")
                    }
                }

            }
        }
        }
    }
}

task generateJSONFormattedEucDistEmaPerPhoneme() {
    dependsOn computeEucDistEMAPerPhoneme


    def input_f = new File("$buildDir/$eval_name/global/dist_euc_ema_per_phoneme.csv")
    def json_formatted_f = new File("$buildDir/$eval_name/global/dist_euc_ema_per_phoneme.json")
    def weights_activated = false
    def dim_weights = 0
    config.models.cmp.streams.each { stream ->
        if (stream.kind == "weight") {
            weights_activated = true
            dim_weights = stream.order + 1
        }
    }

    outputs.files json_formatted_f
    doLast {
        def prev_utt = ""
        double[][] src;
        double[][] tgt;
        double[][] src_weight;
        double[][] tgt_weight;
        def loading = new LoadingHelpers();

        // Building map
        def val = [:]
        input_f.eachLine { line, count ->
            if (!line.startsWith("#")) {


                def elts = line.split()
                if (!(elts[0] in val)) {
                    val[elts[0]] = []
                }


                if (elts[0] != prev_utt) {
                    prev_utt = elts[0]
                    if (eval_name.contains("weight"))
                    {
                        //
                        src = loading.loadFloatBinary("$buildDir/ema/ori/${elts[0]}.ema",channels.size()*3); // FIXME: hardcoded frame size
                        tgt = loading.loadFloatBinary("$buildDir/ema/gen/${elts[0]}.ema", channels.size()*3); // FIXME: hardcoded frame size
                        src_weight = loading.loadFloatBinary("$nat_dir/weight/${elts[0]}.weight", dim_weights);
                        tgt_weight = loading.loadFloatBinary("$synth_dir/imposed_dur/${elts[0]}.weight", dim_weights);
                    }
                    else
                    {
                        //
                        src = loading.loadFloatBinary("${nat_dir}/ema/${elts[0]}.ema", channels.size()*3); // FIXME: hardcoded frame size
                        tgt = loading.loadFloatBinary("${synth_dir}/imposed_dur/${elts[0]}.ema", channels.size()*3); // FIXME: hardcoded frame size
                    }
                }




                // FIXME: we assume actually that we sequentially add everything
                def id_frame = Integer.parseInt(elts[1])
                if (id_frame >= val[elts[0]].size()) {
                    val[elts[0]] << [:]
                    val[elts[0]][id_frame]["coils"] = [:]
                }

                val[elts[0]][id_frame]["phone"] = elts[2]
                val[elts[0]][id_frame]["phone_class"] = map_class_phone[elts[2]]
                val[elts[0]][id_frame]["coils"][elts[3]] = [:]
                ["x", "y", "z"].eachWithIndex { pos, idx ->

                    val[elts[0]][id_frame]["coils"][elts[3]][pos] = [:]
                    val[elts[0]][id_frame]["coils"][elts[3]][pos]["natural"] = src[id_frame][channels.indexOf(elts[3])*3+idx]
                    val[elts[0]][id_frame]["coils"][elts[3]][pos][eval_name] = tgt[id_frame][channels.indexOf(elts[3])*3+idx]

                }

                if (weights_activated) {
                    val[elts[0]][id_frame]["phonemeWeights"] = [:]
                    val[elts[0]][id_frame]["phonemeWeights"]["natural"] = src_weight[id_frame]
                    val[elts[0]][id_frame]["phonemeWeights"][eval_name] = tgt_weight[id_frame]
                }

                val[elts[0]][id_frame]["coils"][elts[3]]["distances"] = [:]
                val[elts[0]][id_frame]["coils"][elts[3]]["distances"]["euclidian"] = Float.parseFloat(elts[4])
            }
        }

        def output_list = []
        val.each {utt, frames ->
            frames.eachWithIndex {frame, id_frame ->
                def tmp = ["utterance":utt, "frame":id_frame, "time":id_frame*0.005] + frame
                output_list << tmp
            }
        }

        def json = groovy.json.JsonOutput.toJson(output_list)
        json_formatted_f.text = JsonOutput.prettyPrint(json.toString())
    }
}

task generateSpecificReport() {
    def ema_activated = false

    def input_f = new File("$buildDir/$eval_name/global/dist_euc_ema_per_phoneme.csv")
    def summary_output_f = new File("$buildDir/$eval_name/global/per_phoneme_report.csv")
    config.models.cmp.streams.each { stream ->
        if ((stream.kind == "ema") || (stream.kind == "weight")) {
            ema_activated = true
            dependsOn generateJSONFormattedEucDistEmaPerPhoneme
            outputs.files summary_output_f
        }
    }

    doLast {

        if (ema_activated){
            // Loading raw information
            def val = [:]
            input_f.eachLine { line ->
                if (!line.startsWith("#")) {
                    def elts = line.split()
                    elts.each {
                        if (!(elts[2] in val)) {
                            val[elts[2]] = [:]
                        }

                        if (!(elts[3] in val[elts[2]])) {
                            val[elts[2]][elts[3]] = []
                        }

                        val[elts[2]][elts[3]] << Double.parseDouble(elts[4])
                    }
                }
            }

            // Generate summary
            summary_output_f.text = "#label\tcoil\tnb_val\teuc_dist(mm)\tstdev\tconfint\n"
            val.each { ph, v ->
                v.each {coil, d ->
                    def dist = new Double[d.size()];
                    d.toArray(dist);
                    def s = new Statistics(dist);
                    summary_output_f << ph <<"\t" << coil <<"\t" << d.size() << "\t" << s.mean() << "\t" << s.stddev() << "\t" << s.confint(0.05) << "\n"
                }
            }
        }
    }
}

/***************************************************************************************************
 *** Plotting
 ***************************************************************************************************/

/* Generate the test part */
(new File(DataFileFinder.getFilePath("list_test"))).each { basename ->
    project(":$basename") {
        buildDir = project.parent.buildDir

        if (false) // (eval_name.contains("weight"))
        {
            task convertNaturalEMAToJson() {

                outputs.files "$buildDir/$eval_name/ema_analysis/json"

                doLast {
                    (new File("$buildDir/$eval_name/ema_analysis/json")).mkdirs()

                    project.exec {
                        commandLine "weights-to-ema-json --input ${nat_dir}/dataset/weights_js/${basename}.json --model ${synth_dir}/../resources/tongue_model.json --output $buildDir/$eval_name/ema_analysis/json/${basename}.json --reference ref --channels T3 T2 T1 --sourceIds 1249 2059 2697".tokenize() // FIXME: harcoded
                        workingDir rootProject.ext.utilsDir
                    }
                }

            }
        }
        else
        {
            task convertNaturalEMAToJson() {

                outputs.files "$buildDir/$eval_name/ema_analysis/json"

                doLast {
                    (new File("$buildDir/$eval_name/ema_analysis/json")).mkdirs()
                    def channel_str = channels.join(",")
                    project.exec {
                        commandLine "python3 ema2json.py -c $channel_str ${nat_dir}/ema/${basename}.ema $buildDir/$eval_name/ema_analysis/json/${basename}.json".tokenize()
                        workingDir rootProject.ext.utilsDir
                    }
                }

            }
        }

        task gatherGenNatEMAInformations() {
            dependsOn convertNaturalEMAToJson

            def output_dir = "$buildDir/$eval_name/ema_analysis/csv"

            outputs.files output_dir

            doLast {

                (new File(output_dir)).mkdirs()
                def output_file = new File("$output_dir/${basename}.csv")
                output_file.text = "id_frame\ttimestamp\tcoil\ttype\taxis\tvalue\n"

                def orig_info = slurper.parseText( (new File("$buildDir/$eval_name/ema_analysis/json/${basename}.json")).text )
                def synth_info = slurper.parseText( (new File("${synth_dir}/imposed_dur/${basename}.json")).text )

                channels.each { c ->

                    orig_info.channels[c].position.eachWithIndex { pos, id ->

                        // Dump info + x
                        if ((id%3) == 0) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tnatural\tx\t$pos\n"
                        }

                        // Dump y
                        if ((id%3) == 1) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tnatural\ty\t$pos\n"
                        }

                        // Dump z + new basename
                        if ((id%3) == 2) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tnatural\tz\t$pos\n"
                        }
                    }

                    synth_info.channels[c].position.eachWithIndex { pos, id ->

                        // Dump info + x
                        if ((id%3) == 0) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tsynthesized\tx\t$pos\n"
                        }

                        // Dump y
                        if ((id%3) == 1) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tsynthesized\ty\t$pos\n"
                        }

                        // Dump z + new basename
                        if ((id%3) == 2) {
                            def id_frame = (id / 3).intValue()
                            def timestamp = id_frame * config.signal.frameshift / 1000
                            output_file << "$id_frame\t$timestamp\t$c\tsynthesized\tz\t$pos\n"
                        }
                    }
                }
            }

        }


        task generateEMATrajectories() {
            dependsOn gatherGenNatEMAInformations

            def output_dirs = "$buildDir/$eval_name/ema_analysis/plots"
            channels.each { c ->
                (new File("$buildDir/$eval_name/ema_analysis/plots/$c")).mkdirs()
            }
            outputs.files "$buildDir/$eval_name/ema_analysis/plots"

            doLast {
                channels.each { c ->
                    project.exec{
                        commandLine "Rscript jsonPlotter.R $buildDir/$eval_name/ema_analysis/csv/${basename}.csv $c $buildDir/$eval_name/ema_analysis/plots/$c/${basename}.pdf".tokenize()
                        workingDir rootProject.ext.utilsDir
                    }
                }
            }
        }
    }
}

task generatePlots() {
    list_file.eachLine { basename ->

        config.models.cmp.streams.each { stream ->
            if (stream.kind == "ema") {
                dependsOn "${basename}:generateEMATrajectories"
            }
            if (stream.kind == "weight") {
        //            dependsOn "${basename}:generateEMATrajectories"
            }
        }
    }
}

/***************************************************************************************************
 *** Decision tree analysis
 ***************************************************************************************************/
def root_tree_analysis_dir = "$buildDir/$eval_name/tree_analysis"
def input_lab_dir = "$buildDir/../../src/mngu0/labels/full/"
(new File(root_tree_analysis_dir)).mkdirs()


task generateListLabels() {
    def output_f = new File("$root_tree_analysis_dir/list_labels.txt")
    outputs.files output_f

    doLast {
         // Reset content file
        output_f.text = ""

        // list labels
        list_file.each { line ->
            (new File("$input_lab_dir/${line}.lab")).each { line_lab ->
                def elts = line_lab.split()
                output_f << elts[2] << "\n"
            }
        }
    }
}

task generateLabelCounts() {
    def output_f = new File("$root_tree_analysis_dir/labels_count.csv")
    outputs.files output_f

    doLast {
         // Reset content file
        output_f.text = "#label\tnb. instances\n"

        // list labels
        def map_labels = [:]
        list_file.each { line ->
            (new File("$input_lab_dir/${line}.lab")).each { line_lab ->
                def elts = line_lab.split()
                if (!(elts[2] in map_labels)) {
                    map_labels[elts[2]] = 0
                }

                map_labels[elts[2]] += 1
            }
        }

        map_labels.each { lab, nb ->
            output_f << "$lab\t$nb\n"
        }
    }
}

task mapLabelDecisionTreePathes() {
    dependsOn generateListLabels

    def output_f= []
    def kinds = ["dur"]
    def states = [2]

    config.models.cmp.streams.each { stream ->
        def kind = stream.kind
        kinds << kind
        states << 4
    }
    kinds.each { kind ->
        output_f << new File("$root_tree_analysis_dir/path_${kind}.txt")
    }
    outputs.files output_f

    doLast {
        def label_list_path = "$root_tree_analysis_dir/list_labels.txt"


        kinds.eachWithIndex { kind,i ->
            def tree_path = "$model_file/trees/${kind}.inf"
            def state = 4 // FIXME: hardcoded middle state
            exec {
                commandLine "perl get_path.pl -s ${states[i]} $tree_path $label_list_path ${output_f[i]}".tokenize()
                workingDir "$rootProject.ext.utilsDir/tree_analysis"
            }
        }
    }
}

task countPaths() {
    dependsOn mapLabelDecisionTreePathes

    def output_f = []
    def path_f = []
    def kinds = ["dur"]

    config.models.cmp.streams.each { stream ->
        def kind = stream.kind
        kinds << kind
    }
    kinds.each { kind ->
        output_f << new File("$root_tree_analysis_dir/path_count_${kind}.csv")
        path_f << new File("$root_tree_analysis_dir/path_${kind}.txt")
    }
    outputs.files output_f

    doLast {

        kinds.eachWithIndex { kind,i ->
            output_f[i].text = "#path\tnb. elts\n"

            // list labels
            def map_paths = [:]
            path_f[i].each {line ->
                if (!(line in map_paths)) {
                    map_paths[line] = 0
                }

                map_paths[line] += 1
            }

            map_paths.each {path, nb ->
                output_f[i] << "$path\t$nb\n"
            }
        }
    }
}

task countNodes() {
    dependsOn mapLabelDecisionTreePathes

    def output_f = []
    def path_f = []
    def kinds = ["dur"]

    config.models.cmp.streams.each { stream ->
        def kind = stream.kind
        kinds << kind
    }
    kinds.each { kind ->
        output_f << new File("$root_tree_analysis_dir/node_count_${kind}.csv")
        path_f << new File("$root_tree_analysis_dir/path_${kind}.txt")
    }
    outputs.files output_f

    doLast {

        kinds.eachWithIndex { kind,i ->
            output_f[i].text = "#node\tnb. elts\n"

            // list labels
            def map_nodes = [:]
            path_f[i].each {line ->
                def elts = line.split(" => ")
                elts.each { elt ->
                    elt = elt.replaceAll(/[!()]/, "")
                    if (!(elt in map_nodes)) {
                        map_nodes[elt] = 0
                    }

                    map_nodes[elt] += 1
                }
            }

            map_nodes = map_nodes.sort {it.value}
            map_nodes.each {node, nb ->
                output_f[i] << "$node\t$nb\n"
            }
        }
    }

}

task generateTreeAnalysis() {
    dependsOn generateLabelCounts, countPaths, countNodes
}

/***************************************************************************************************
 *** Publishing part
 ***************************************************************************************************/

group "org.m2ci.msp"
version '0.1'

distributions {
  main {
    contents {
        from generateGlobalReport
        from generateSpecificReport
        from generatePlots
        from generateTreeAnalysis
        from "$buildDir/$eval_name"
    }
  }
}

publishing {
  publications {
    main(MavenPublication) {
      artifact distZip
    }
  }
  repositories {
    maven {
      url "http://localhost:8081/artifactory/data-release-local/"
      credentials {
        username = findProperty('cloudarkUser')
        password = findProperty('cloudarkApiKey')
      }
    }
  }
}
