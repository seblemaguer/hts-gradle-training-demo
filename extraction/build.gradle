buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath group: "com.googlecode.json-simple", name:"json-simple", version:"1.1"
    }
}
// "basic" configuration in it

apply plugin: 'groovy'
apply plugin: 'java'

group 'de.dfki.mary'
version '0.5.2-SNAPSHOT'

repositories {
    mavenCentral()
    maven {
        url 'http://localhost:8081/artifactory/local'
        credentials {
            username = findProperty('cloudarkUser')
            password = findProperty('cloudarkApiKey')
        }
    }
}

configurations {
    data
    tonguemodel
}

dependencies {
    compile "org.codehaus.groovy:groovy-all:2.2"
    data group: 'org.m2ci.msp', name: 'mngu0-data-tongueModelWeights-fixedSpeaker', version: '0.1-SNAPSHOT', ext:'zip'
}

ext {
    config_file = new File("../src/configuration/" + System.getProperty("eval_name") + ".json")
}

import groovy.json.* // To load the JSON configuration file
import java.util.*

def slurper = new JsonSlurper()
def config = slurper.parseText( config_file.text )


/***************************************************************************************
 ** Stupid weights part (as weights are of course not extracted in a standard way...)
 ***************************************************************************************/

import java.util.ArrayList;
import java.util.StringTokenizer;

import java.io.File;
import java.io.InputStreamReader;
import java.io.BufferedReader;
import java.io.FileReader;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.StandardOpenOption;

import org.json.simple.JSONObject;
import org.json.simple.JSONArray;
import org.json.simple.parser.ParseException;
import org.json.simple.parser.JSONParser;

if (System.getProperty("eval_name").contains("weight"))
{

    def NB_WEIGHTS = 13;
    def FLOAT_SIZE = Float.SIZE/8; // Float size in nb bytes...
    task extractWeightArchive {
        def datasetDir = file("$buildDir/dataset/raw")
        outputs.files datasetDir

        doLast {
            copy {
                from configurations.data.collect { zipTree(it) }
                into datasetDir
            }
        }
    }

    task cleanDataSetArchitecture {
        dependsOn extractWeightArchive

        doLast {
            (new File("$buildDir/dataset/weights_js")).mkdirs()
            (new File("$buildDir/weight/")).mkdirs() // FIXME: misplaced

            fileTree("$buildDir/dataset/raw"){include '**/fittedFixedSpeaker.json'}.each { path ->
                def tmp = path.toString().replaceAll(/\/fittedFixedSpeaker.json/) { all -> "" }
                tmp = tmp.replaceAll(/.*\//) { all -> "" }
                copy {
                    from path.getParent()
                    into "$buildDir/dataset/weights_js"
                    rename { tmp }
                }
            }
        }
    }


    (new File(DataFileFinder.getFilePath(config.data.list_files))).eachLine{ basename ->
        project(":$basename") {
            buildDir = project.parent.buildDir

            project.task('extract') {

                dependsOn ":cleanDataSetArchitecture"

                def input_filename = "$buildDir/dataset/weights_js/${basename}.json"
                inputs.files input_filename
                File output_file = new File("$buildDir/weight/${basename}.json");
                outputs.files output_file

                doLast {
                    JSONParser parser = new JSONParser();
                    JSONArray frames = (JSONArray) parser.parse(new FileReader(input_filename));

                    ByteBuffer bf = ByteBuffer.allocate((frames.size()*NB_WEIGHTS*FLOAT_SIZE).intValue());
                    bf.order(ByteOrder.LITTLE_ENDIAN);

                    for (Object frame: frames)
                    {
                        JSONArray weights = (JSONArray) ((JSONObject) frame).get("phonemeWeights");
                        for (Object weight: weights)
                        {
                            bf.putFloat(((Double)weight).floatValue());
                        }
                    }

                    // Output
                    Files.write(output_file.toPath(), bf.array());
                }
            }
        }
    }

    /* Generate the test part */
    (new File(DataFileFinder.getFilePath("list_test"))).eachLine{ basename ->
        project(":$basename") {
            buildDir = project.parent.buildDir

            project.task('extract') {

                dependsOn ":cleanDataSetArchitecture"

                def input_filename = "$buildDir/dataset/weights_js/${basename}.json"
                inputs.files input_filename
                File output_file = new File("$buildDir/weight/${basename}.weight");
                outputs.files output_file

                doLast {
                    JSONParser parser = new JSONParser();
                    JSONArray frames = (JSONArray) parser.parse(new FileReader(input_filename));


                    ByteBuffer bf = ByteBuffer.allocate((frames.size()*NB_WEIGHTS*FLOAT_SIZE).intValue());
                    bf.order(ByteOrder.LITTLE_ENDIAN);

                    for (Object frame: frames)
                    {
                        JSONArray weights = (JSONArray) ((JSONObject) frame).get("phonemeWeights");
                        for (Object weight: weights)
                        {
                            bf.putFloat(((Double)weight).floatValue());
                        }
                    }

                    // Output
                    Files.write(output_file.toPath(), bf.array());
                }
            }
        }
    }
}

/***************************************************************************************
 ** Standard extraction
 ***************************************************************************************/
if (!System.getProperty("eval_name").contains("weight"))
{
    (new File(DataFileFinder.getFilePath(config.data.list_files))).eachLine{ basename ->
        project(":$basename") {
            buildDir = project.parent.buildDir
            config_file = confifig_le
            apply plugin: "de.dfki.mary.coefficientextraction"
        }
    }

    /* Generate the test part */
    (new File(DataFileFinder.getFilePath("list_test"))).eachLine{ basename ->
        project(":$basename") {
            buildDir = project.parent.buildDir
            apply plugin: "de.dfki.mary.coefficientextraction"
        }
    }
}

task extract() {
    (new File(DataFileFinder.getFilePath(config.data.list_files))).eachLine { basename ->
        dependsOn ":${basename}:extract"
    }

    (new File(DataFileFinder.getFilePath("list_test"))).eachLine { basename ->
        dependsOn ":${basename}:extract"
    }
}
